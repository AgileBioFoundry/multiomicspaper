{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cobra\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from cobra.exceptions import OptimizationError, Infeasible\n",
    "from typing import NewType, Dict, List, Any, Counter\n",
    "from enum import Enum\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User parameters passed to the program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_params = {\n",
    "    'host': 'ecoli', # ecoli or ropacus\n",
    "    'modelfile': 'iJO1366_MVA.json',\n",
    "    'timestart': 0.0,\n",
    "    'timestop': 8.0,\n",
    "    'numpoints': 9,\n",
    "    'reactants': ['glc__D_e', 'nh4_e', 'pi_e', 'so4_e', 'mg2_e', 'k_e', 'na1_e', 'cl_e'],\n",
    "    'initial_substrates': [22.203, 18.695, 69.454, 2.0, 2.0, 21.883, 103.7, 27.25],\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare some variables and types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enumerations\n",
    "class Omics(Enum):\n",
    "    \"\"\"Enumeration with supported omics data types.\"\"\"\n",
    "    PROTEOMICS = 0\n",
    "    TRANSCRIPTOMICS = 1\n",
    "    METABOLOMICS = 2\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'{str(self.name).lower()}'\n",
    "    \n",
    "# Type annotations\n",
    "Filename = NewType('Filename', str)\n",
    "\n",
    "# Constants\n",
    "UNIPROT_URL = '''https://www.uniprot.org/uploadlists/'''\n",
    "CTS_URL = '''https://cts.fiehnlab.ucdavis.edu/rest/convert/'''\n",
    "# HOST NAME\n",
    "HOST_NAME: str = user_params['host'] \n",
    "# TODO: Move some constants to variables by program arguments\n",
    "DATA_FILE_PATH: Filename = Filename('data')\n",
    "# Output file path\n",
    "OUTPUT_FILE_PATH: Filename = Filename('data/output')\n",
    "# INCHIKEY_TO_CID_MAP_FILE_PATH: mapping file path to map inchikey to cids\n",
    "INCHIKEY_TO_CID_MAP_FILE_PATH: Filename = Filename('mapping') \n",
    "# MODEL_FILENAME: Filename = Filename('iECIAI39_1322.xml')  # E. coli\n",
    "MODEL_FILENAME: Filename = Filename('reannotated_base_v3.sbml')  # R. opacus\n",
    "\n",
    "# NOTE: user input to the program\n",
    "REACTION_ID_ECOLI: str = 'BIOMASS_Ec_iJO1366_core_53p95M'  # E. coli\n",
    "REACTION_ID: str = 'biomass_target'  # R. opacus\n",
    "# REACTION_ID: str = 'SRC_C00185_e'  # R. opacus\n",
    "GENE_IDS_DBS: List[str] = ['kegg.genes']  # R. opacus\n",
    "# GENE_IDS_DBS: List[str] = ['uniprot', 'goa', 'ncbigi']  # E. coli\n",
    "UNITS: Dict[Omics, str] = {\n",
    "    Omics.PROTEOMICS: 'proteins/cell',\n",
    "    Omics.TRANSCRIPTOMICS: \"FPKM\",\n",
    "    Omics.METABOLOMICS: \"mg/L\"\n",
    "}\n",
    "# Fix the flux value to -15 as we have data for this constraint\n",
    "LOWER_BOUND: int = -15\n",
    "UPPER_BOUND: int = -15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Ecoli class that has all the mothds to generate the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ecoli():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.time_series_omics_data = {}\n",
    "        self.LOWER_BOUND = -15\n",
    "        self.UPPER_BOUND = 1000\n",
    "\n",
    "\n",
    "    def generate_time_series_data(self, model, condition):\n",
    "\n",
    "        # intiializing omics dictionaries to contain data across timepoints\n",
    "        proteomics_list: List = []\n",
    "        transcriptomics_list: List = []\n",
    "        fluxomics_list: List = []\n",
    "        metabolomics_list: List = []\n",
    "       \n",
    "        # The whole idea of using \"batch simulation concepts from Joonhoon\" is to\n",
    "        # estimate glucose consumption values (written as flux constraints below)\n",
    "        # is a more realistic way\n",
    "        \n",
    "        # In order to update flux values and estimate concentration of glucose, we \n",
    "        # assume concentrations at t = 0h to be \"subs0\" (refer to batch simulation notebook).\n",
    "        # We also assume \"volume\" = 1.0 and OD at t = 0h (cell0)\n",
    "        # Assume time points, you can keep this time points or change them to what Joonhoon has\n",
    "        # Step1: Evaluate flux of glucose at current time point by this equation:\n",
    "        # model.reactions.get_by_id(k).lower_bound = max(model.reactions.get_by_id(k).lower_bound,\n",
    "        #                                                  -subs.loc[t,v]*volume/cell[t]/delt)\n",
    "        # Step2: Solve the model using the function \"get_optimized_solution\" present below and generate\n",
    "        # data for that time point\n",
    "        # Step 3: Calculate mu where mu = solution(biomass)\n",
    "        # Step 4: Calculate OD for next time point: cell[t+delt] = cell[t]*np.exp(mu*delt)\n",
    "        # Step 5: Calculate glucose for next time point t+deltat: \n",
    "        # subs.loc[t+delt,v] = max(subs.loc[t,v]-sol[k]/mu*cell[t]*(1-np.exp(mu*delt)),0.0)\n",
    "        # Go back to step 1\n",
    "        \n",
    "        time_series_omics_data = {}\n",
    "\n",
    "        # time steps to calculate the biomass production for\n",
    "        t0 = user_params['timestart']\n",
    "        tf = user_params['timestop']\n",
    "        points = user_params['numpoints']\n",
    "        tspan, delt = np.linspace(t0, tf, points, dtype='float64', retstep=True)\n",
    "\n",
    "        # step interval\n",
    "        # delt = tspan[1] - tspan[0]\n",
    "\n",
    "        # panda series containing OD values for the timepionts\n",
    "        cell = pd.Series(index=tspan)\n",
    "        cell0 = 0.01 # in gDW/L\n",
    "        cell[t0] = cell0\n",
    "\n",
    "        # reactants\n",
    "        comp = user_params['reactants']\n",
    "\n",
    "        # Dataframe containing substrates\n",
    "        subs = pd.DataFrame(index=tspan, columns=comp)\n",
    "        # initial substrate vlaues\n",
    "        subs0 = user_params['initial_substrates']# in mM\n",
    "        subs.loc[t0] = subs0\n",
    "\n",
    "        # Panda series containing the isopentanol concentrations\n",
    "        # and solutions to the wild type after adding isopentenol\n",
    "        # pathway and introducing isopentenol fluzes and solving for the \n",
    "        # optimum solution for maimum biomass\n",
    "        conc_iso = pd.Series(index=tspan)\n",
    "        conc_iso[tspan[0]] = 0.0\n",
    "\n",
    "        sol_time_wild = pd.Series(index=tspan)\n",
    "        \n",
    "        # exterior substrates\n",
    "        subs_ext = {r.id: r.reactants[0].id for r in model.exchanges if r.reactants[0].id in comp}\n",
    "\n",
    "        # NOTE: put the body of the for loop inside a function\n",
    "        for t in tspan:\n",
    "            # Not changing the model but adding constraints for each time point\n",
    "            with model:\n",
    "                for k, v in subs_ext.items():\n",
    "                    # why do we set volume to one? Is it arbitrary?\n",
    "                    volume = 1.0\n",
    "                    # print(model.reactions.get_by_id(k).lower_bound)\n",
    "                    # print(-subs.loc[t,v]*volume/cell[t]/delt)\n",
    "\n",
    "                    # Set global reactions bounds (in addition to local)\n",
    "                    # set the lower bound to the maximum of the lower bound in the model and the change of glucose \n",
    "                    model.reactions.get_by_id(k).lower_bound = max(model.reactions.get_by_id(k).lower_bound, -subs.loc[t,v]*volume/cell[t]/delt)\n",
    "                    self.LOWER_BOUND = model.reactions.get_by_id(k).lower_bound\n",
    "                    # print(self.LOWER_BOUND)\n",
    "                    # self.UPPER_BOUND = -15\n",
    "#                     cobra_config = cobra.Configuration()\n",
    "#                     cobra_config.bounds = self.LOWER_BOUND, self.UPPER_BOUND\n",
    "\n",
    "                    # get fake proteomics data and write it to XLSX file\n",
    "                    condition = 1\n",
    "                    proteomics, transcriptomics, fluxomics, metabolomics, solution = self.generate_fake_data(model, condition)\n",
    "\n",
    "                    # Step 3: Calculate mu where mu = solution(biomass)\n",
    "                    mu = solution[REACTION_ID_ECOLI]\n",
    "\n",
    "                    # Step 4: Calculate OD for next time point: cell[t+delt] = cell[t]*np.exp(mu*delt)\n",
    "                    # print(\"===================\")\n",
    "                    # print(\"t, t+delt, cell[t]: \", t, t+delt, cell[t])\n",
    "                    # print(\"cell[t]*np.exp(mu*delt): \", cell[t]*np.exp(mu*delt) )\n",
    "                    # print(\"cell[t], mu, delt: \", cell[t], mu, delt)\n",
    "                    cell[t+delt] = cell[t]*np.exp(mu*delt)\n",
    "                    # print(\"t+delt, cell[t+delt]: \", t+delt, cell[t+delt])\n",
    "                    # if np.isnan(cell[t+delt]):\n",
    "                    #     print(\"I am here\")\n",
    "                    #     print(\"cell: \", cell)\n",
    "                    #     return\n",
    "\n",
    "                    # Step 5: Calculate glucose for next time point t+deltat:\n",
    "                    subs.loc[t+delt,v] = max(subs.loc[t,v]-solution[k]/mu*cell[t]*(1-np.exp(mu*delt)),0.0) \n",
    "\n",
    "                    # appending the dictionaries to a master list that keeps track of the timepoints associated with the data generated\n",
    "                    proteomics_list.append((proteomics, t))\n",
    "                    transcriptomics_list.append((transcriptomics, t))\n",
    "                    fluxomics_list.append((fluxomics, t))\n",
    "                    metabolomics_list.append((metabolomics, t))\n",
    " \n",
    "                # optimize model using pFBA after inducing isopentenol and formate formation \n",
    "                # and get isopentenol concentrations\n",
    "                # NOTE: pass the training file as an argument from the cli\n",
    "                training_data_file = f'{DATA_FILE_PATH}/training_data_8genes.csv'\n",
    "                sol_time_wild = self.generate_isopentenol_concentrations(model, sol_time_wild, training_data_file, t, tspan, delt, cell, subs, subs_ext, conc_iso)\n",
    "                # print(sol_time_wild)\n",
    "\n",
    "        # generate training data for reactions with isopentenol production after optimizing model using MOMA\n",
    "        # NOTE: This is not working as I do not have the 'cplex' solver installed and it is looking for a \n",
    "        # qp-solver that is not there to solve the MOMA optimization\n",
    "        # Have to run this in the jprime server\n",
    "        \n",
    "        # self.generate_isopentenol_and_solution_for_biomass_using_moma(model, sol_time_wild, training_data_file, tspan, delt, cell, subs, subs_ext)\n",
    "        # print(type(subs))\n",
    "        # print(subs)\n",
    "        # sys.exit()\n",
    "\n",
    "        time_series_omics_data = {'proteomics': proteomics_list, 'transcriptomics': transcriptomics_list, 'fluxomics': fluxomics_list, 'metabolomics': metabolomics_list}\n",
    "        \n",
    "        # write all the data generated\n",
    "        self.write_experiment_description_file(condition)\n",
    "        self.write_omics_files(time_series_omics_data)\n",
    "        self.write_OD_data(cell)\n",
    "        # write external metabolites in subs: Ammonia and glucose and isoprenol concentrations\n",
    "        self.write_external_metabolite(subs, conc_iso)\n",
    "\n",
    "\n",
    "    # This uses the modified E. Coli model that has the added isopentenol pathway\n",
    "    # QUESTION: DO we need to add the isopentenol pathway to it, if not provided?DO we need to check it?\n",
    "    def generate_isopentenol_concentrations(self, model, sol_time_wild, training_data_file, timepoint, tspan, delt, cell, subs, subs_ext, conc_iso):\n",
    "        iso = 'EX_isoprenol_e'\n",
    "        df = pd.read_csv(training_data_file)\n",
    "\n",
    "        # Calculating the number of reactions that should be modified (n_genes) and \n",
    "        # number of strains for which isoprenol concentration should be estimated \n",
    "        n_reactions = df.shape[1] - 1\n",
    "        n_instances = df.shape[0] - 1\n",
    "        # print(n_reactions,n_instances)\n",
    "\n",
    "        # Inserting the isoprenol concentration as the last column in the dataframe\n",
    "        df.insert(loc=n_reactions+1, column='Isoprenol Concentration (mM)', value=None)\n",
    "\n",
    "        iso_cons = model.problem.Constraint(model.reactions.EX_isoprenol_e.flux_expression,\n",
    "                                lb = 0.20)\n",
    "        model.add_cons_vars(iso_cons)\n",
    "        for_cons = model.problem.Constraint(model.reactions.EX_for_e.flux_expression,\n",
    "                                lb = 0.10)\n",
    "        model.add_cons_vars(for_cons)\n",
    "        # display(model.summary())\n",
    "        sol_t = model.optimize()\n",
    "        # storing the solution for each timepoint which are going to be reference solutions for moma (see below)\n",
    "        sol_time_wild[timepoint] = sol_t\n",
    "        mu = sol_t[REACTION_ID_ECOLI]\n",
    "\n",
    "        if sol_t.status == 'optimal' and mu > 1e-6:\n",
    "            # Calculating next time point's OD\n",
    "            cell[timepoint+delt] = cell[timepoint]*np.exp(mu*delt)\n",
    "            for k, v in subs_ext.items():\n",
    "                # Calculating substrate's concentration for next time point\n",
    "                subs.loc[timepoint+delt,v] = max(subs.loc[timepoint,v]-sol_t[k]/mu*cell[timepoint]*(1-np.exp(mu*delt)),0.0)\n",
    "            if sol_t[iso] > 0:\n",
    "                # Calculating isoprenol concentration for next time point\n",
    "                conc_iso.loc[timepoint+delt] = conc_iso.loc[timepoint]-sol_t[iso]/mu*cell[timepoint]*(1-np.exp(mu*delt))\n",
    "            else:\n",
    "                conc_iso.loc[0:t] = 0\n",
    "                conc_iso.loc[timepoint+delt] = conc_iso.loc[timepoint]-sol_t[iso]/mu*cell[timepoint]*(1-np.exp(mu*delt))\n",
    "        else:\n",
    "            cell[timepoint+delt] = cell[timepoint]\n",
    "            for k, v in subs_ext.items():\n",
    "                subs.loc[timepoint+delt,v] = subs.loc[timepoint,v]\n",
    "            conc_iso.loc[timepoint+delt] = conc_iso.loc[timepoint]\n",
    "\n",
    "        return sol_time_wild\n",
    "\n",
    "    def generate_isopentenol_and_solution_for_biomass_using_moma(self, model, sol_time_wild, training_data_file, tspan, delt, cell, subs, subs_ext):\n",
    "        model.solver = 'cplex'\n",
    "        iso = 'EX_isoprenol_e'\n",
    "        df = pd.read_csv(training_data_file)\n",
    "\n",
    "        # The original e.coli iJO1366 model does not have the isoprenol pathway. \n",
    "        # Thus, performing simple flux balance analysis on the model will not allocate \n",
    "        # any flux for isoprenol production reaction. So, we modify the model so that \n",
    "        # it produces a small amount of isoprenol. In addition, we force a small amount \n",
    "        # of formate production which forces the model to activate the 'PFL' reaction.\n",
    "        with model:\n",
    "            # display(model.summary())\n",
    "            # Constraint to force a small amount of isoprenol production\n",
    "            iso_cons = model.problem.Constraint(model.reactions.EX_isoprenol_e.flux_expression,\n",
    "                                        lb = 0.20)\n",
    "            # Adding the constraint to the model\n",
    "            model.add_cons_vars(iso_cons)\n",
    "            # Constraint to force a small amount of formate production which would activate the \"PFL\" reaction\n",
    "            for_cons = model.problem.Constraint(model.reactions.EX_for_e.flux_expression,\n",
    "                                        lb = 0.10)\n",
    "            # Adding the constraint to the model\n",
    "            model.add_cons_vars(for_cons)\n",
    "            WT_FBA_sol = cobra.flux_analysis.pfba(model)\n",
    "            print(WT_FBA_sol.status, WT_FBA_sol[REACTION_ID_ECOLI], WT_FBA_sol[iso])\n",
    "\n",
    "        # Calculating the number of reactions that should be modified (n_genes) and \n",
    "        # number of strains for which isoprenol concentration should be estimated \n",
    "        n_reactions = df.shape[1] - 1\n",
    "        n_instances = df.shape[0] - 1\n",
    "\n",
    "        # Inserting the isoprenol concentration as the last column in the dataframe\n",
    "        df.insert(loc=n_reactions+1, column='Isoprenol Concentration (mM)', value=None)\n",
    "\n",
    "        # Panda series containing the isopentanol concentrations\n",
    "        # and solutions to the wild type after adding isopentenol\n",
    "        # pathway and introducing isopentenol fluzes and solving for the \n",
    "        # optimum solution for maimum biomass\n",
    "        conc_iso = pd.Series(index=tspan)\n",
    "        conc_iso[tspan[0]] = 0.0\n",
    "\n",
    "        volume = 1.0\n",
    "        # For each strain\n",
    "        for i in range(0,n_instances):\n",
    "            # At each time point\n",
    "            for t in tspan:\n",
    "                # Adding constraints to the model at each time point for each strain without globally changing the model\n",
    "                with model:\n",
    "                    for k, v in subs_ext.items():\n",
    "                        model.reactions.get_by_id(k).lower_bound = max(model.reactions.get_by_id(k).lower_bound,\n",
    "                                                                -subs.loc[t,v]*volume/cell[t]/delt)\n",
    "                    # Adding the fluxed modifications for chosen reactions\n",
    "                    cons1 = model.problem.Constraint(model.reactions.ACCOAC.flux_expression, \n",
    "                                                    lb = WT_FBA_sol['ACCOAC']*df.iloc[i,1],\n",
    "                                                    ub = WT_FBA_sol['ACCOAC']*df.iloc[i,1])\n",
    "                    model.add_cons_vars(cons1)\n",
    "                \n",
    "                    cons2 = model.problem.Constraint(model.reactions.MDH.flux_expression,\n",
    "                                                    lb = WT_FBA_sol['MDH']*df.iloc[i,2],\n",
    "                                                    ub = WT_FBA_sol['MDH']*df.iloc[i,2])\n",
    "                    model.add_cons_vars(cons2)\n",
    "                \n",
    "                    cons3 = model.problem.Constraint(model.reactions.PTAr.flux_expression,\n",
    "                                                    lb = WT_FBA_sol['PTAr']*df.iloc[i,3],\n",
    "                                                    ub = WT_FBA_sol['PTAr']*df.iloc[i,3])\n",
    "                    model.add_cons_vars(cons3)\n",
    "                \n",
    "                    cons4 = model.problem.Constraint(model.reactions.CS.flux_expression,\n",
    "                                                    lb = WT_FBA_sol['CS']*df.iloc[i,4],\n",
    "                                                    ub = WT_FBA_sol['CS']*df.iloc[i,4])\n",
    "                    model.add_cons_vars(cons4)\n",
    "                \n",
    "                    cons5 = model.problem.Constraint(model.reactions.ACACT1r.flux_expression,\n",
    "                                                    lb = WT_FBA_sol['ACACT1r']*df.iloc[i,5],\n",
    "                                                    ub = WT_FBA_sol['ACACT1r']*df.iloc[i,5])\n",
    "                    model.add_cons_vars(cons5)\n",
    "                \n",
    "                    cons6 = model.problem.Constraint(model.reactions.PPC.flux_expression,\n",
    "                                                    lb = WT_FBA_sol['PPC']*df.iloc[i,6],\n",
    "                                                    ub = WT_FBA_sol['PPC']*df.iloc[i,6])\n",
    "                    model.add_cons_vars(cons6)\n",
    "                \n",
    "                    cons7 = model.problem.Constraint(model.reactions.PPCK.flux_expression,\n",
    "                                                    lb = WT_FBA_sol['PPCK']*df.iloc[i,7],\n",
    "                                                    ub = WT_FBA_sol['PPCK']*df.iloc[i,7])\n",
    "                \n",
    "                    model.add_cons_vars(cons7)\n",
    "                \n",
    "                    cons8 = model.problem.Constraint(model.reactions.PFL.flux_expression,\n",
    "                                                    lb = WT_FBA_sol['PFL']*df.iloc[i,8],\n",
    "                                                    ub = WT_FBA_sol['PFL']*df.iloc[i,8])\n",
    "                \n",
    "                    model.add_cons_vars(cons8)\n",
    "                    \n",
    "                    # Reference solution calculated for each time point in above cell for wild type\n",
    "                    sol1 = sol_time_wild[t]\n",
    "                    print(sol_time_wild)\n",
    "                    print(sol1)\n",
    "\n",
    "                    # Moma solution for each time point\n",
    "                    sol2 = cobra.flux_analysis.moma(model, solution=sol1, linear=False)\n",
    "                    mu = sol2[REACTION_ID_ECOLI]\n",
    "                    print(i,t, sol2.status, mu)\n",
    "                    if sol2.status == 'optimal' and mu > 1e-6:\n",
    "                        cell[t+delt] = cell[t]*np.exp(mu*delt)\n",
    "                        for k, v in subs_ext.items():\n",
    "                            subs.loc[t+delt,v] = max(subs.loc[t,v]-sol2[k]/mu*cell[t]*(1-np.exp(mu*delt)),0.0)\n",
    "                        if sol2[iso] > 0:\n",
    "                            conc_iso.loc[t+delt] = conc_iso.loc[t]-sol2[iso]/mu*cell[t]*(1-np.exp(mu*delt))\n",
    "                        else:\n",
    "                            conc_iso.loc[0:t] = 0\n",
    "                            conc_iso.loc[t+delt] = conc_iso.loc[t]-sol2[iso]/mu*cell[t]*(1-np.exp(mu*delt))\n",
    "                    else:\n",
    "                        cell[t+delt] = cell[t]\n",
    "                        for k, v in subs_ext.items():\n",
    "                            subs.loc[t+delt,v] = subs.loc[t,v]\n",
    "                        conc_iso.loc[t+delt] = conc_iso.loc[t]\n",
    "            \n",
    "            \n",
    "            # Storing the final concentration for all strains\n",
    "            df.iloc[i,9] = conc_iso.iloc[-1]\n",
    "            print(conc_iso)\n",
    "            print(i,sol2[iso],conc_iso.iloc[-1])\n",
    "\n",
    "            # write out the training dataset with isopentenol production concentrations\n",
    "            # filename = 'training_data_8genes_withiso.csv'\n",
    "            # self.write_training_data_with_isopentenol(df, filename)\n",
    "\n",
    "    def generate_fake_data(self, model, condition):\n",
    "        \"\"\"\n",
    "\n",
    "        :param model: cobra model object\n",
    "        :param solution: solution for the model optimization using cobra\n",
    "        :param data_type: defines the type of -omics data to generate (all by default)\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        self.proteomics = {}\n",
    "        self.transcriptomics = {}\n",
    "        self.fluxomics = {}\n",
    "        self.metabolomics = {}\n",
    "\n",
    "        # reaction_id of choice passed to the function# hardcoded here for this particular file (Need to convert this to an interactive cli program)\n",
    "        reaction_id = REACTION_ID_ECOLI\n",
    "\n",
    "        # while condition:\n",
    "            # print(\"Condition parameter: \", condition)\n",
    "        condition-=1\n",
    "        solution = self.get_optimized_solution(model, reaction_id)\n",
    "        # solution: cobra.Solution = cobra.core.solution.get_solution(\n",
    "        #     model, raise_error=False)\n",
    "\n",
    "        proteomics, transcriptomics, fluxomics = self.get_proteomics_transcriptomics_fluxomics_data(model, solution, condition)\n",
    "        \n",
    "        metabolomics = self.get_metabolomics_data(model, condition)\n",
    "        \n",
    "        return (proteomics, transcriptomics, fluxomics, metabolomics, solution)\n",
    "\n",
    "    # NOTE: \n",
    "    def read_pubchem_id_file(self):\n",
    "        inchikey_to_cid = {}\n",
    "        filename = f'{INCHIKEY_TO_CID_MAP_FILE_PATH}/inchikey_to_cid.txt'\n",
    "        with open(filename, 'r') as fh:\n",
    "                try:\n",
    "                    line = fh.readline()\n",
    "                    while line:\n",
    "                        # checking to ignore inchikey records with no cid mappings\n",
    "                        if (len(line.split()) > 1):\n",
    "                            inchikey_to_cid[line.split()[0]] = 'CID:'+line.split()[1]\n",
    "                        else:\n",
    "                            inchikey_to_cid[line.strip()] = None\n",
    "\n",
    "                        line = fh.readline()\n",
    "                # NOTE: propagated exception, raise\n",
    "                except Exception as ex:\n",
    "                    print(\"Error in reading file!\")\n",
    "                    print(ex)\n",
    "        # fh.close()\n",
    "\n",
    "        return inchikey_to_cid\n",
    "\n",
    "    def get_metabolomics_data(self, model, condition):\n",
    "        \"\"\"\n",
    "\n",
    "        :param model:\n",
    "        :param condition:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        metabolomics = {}\n",
    "        # get metabolites\n",
    "        # NOTE: Need to find a better algorithm. This is O(n^3)\n",
    "\n",
    "        # read the inchikey to pubchem ids mapping file\n",
    "        inchikey_to_cid = {}\n",
    "        inchikey_to_cid = self.read_pubchem_id_file()\n",
    "\n",
    "        for met in model.metabolites:\n",
    "            # get associated reactions\n",
    "            for reaction in list(met.reactions):\n",
    "                # get dictionary of associated metabolites and their concentrations\n",
    "                for metabolite, conc in reaction._metabolites.items():\n",
    "                    if metabolite.id == met.id:\n",
    "                        # map the BIGG ids to CIDs using the inchikeys in the metabolites and the ampping file\n",
    "                        # that we have generated from Pubchem\n",
    "                        # remember that not all Inchikeys dont have a mappping to a CIDs and there are\n",
    "                        # multiple mappings for some Inchikeys\n",
    "                        if 'inchi_key' in met.annotation:\n",
    "                            if type(met.annotation['inchi_key']) is list:\n",
    "                                inchi_key = met.annotation['inchi_key'][0]\n",
    "                            else:\n",
    "                                inchi_key = met.annotation['inchi_key']\n",
    "                            \n",
    "                            if inchi_key in inchikey_to_cid.keys():\n",
    "                                if inchikey_to_cid[inchi_key] not in metabolomics.keys():\n",
    "                                    if inchikey_to_cid[inchi_key] is not None:\n",
    "                                        metabolomics[inchikey_to_cid[inchi_key]] = abs(conc)\n",
    "                                else:\n",
    "                                    if inchikey_to_cid[inchi_key] is not None:\n",
    "                                        metabolomics[inchikey_to_cid[inchi_key]] += abs(conc)\n",
    "            # getting number of associated reactions and averaging the metabolic concentration value\n",
    "            num_reactions = len(list(met.reactions))\n",
    "\n",
    "            # check if inchi_key attribite present else ignore metabolite\n",
    "            if 'inchi_key' in met.annotation.keys() and inchi_key in inchikey_to_cid.keys():\n",
    "                if inchikey_to_cid[inchi_key] is not None:\n",
    "                    metabolomics[inchikey_to_cid[inchi_key]]/=num_reactions\n",
    "\n",
    "        return metabolomics\n",
    "\n",
    "    def get_proteomics_transcriptomics_fluxomics_data(self, model, solution, condition):\n",
    "        \"\"\"\n",
    "\n",
    "        :param model:\n",
    "        :param solution:\n",
    "        :param condition:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        # pre-determined linear constant (NOTE: Allow user to set this via parameter)\n",
    "        # DISCUSS!!\n",
    "        k = 0.8\n",
    "        q = 0.06\n",
    "\n",
    "        proteomics = {}\n",
    "        transcriptomics = {}\n",
    "        fluxomics = {}\n",
    "\n",
    "        # print(solution.fluxes['EX_cm_e'])\n",
    "        rxnIDs = solution.fluxes.keys()\n",
    "        for rxnId in rxnIDs:\n",
    "            reaction = model.reactions.get_by_id(rxnId)\n",
    "            for gene in list(reaction.genes):\n",
    "\n",
    "                # this will ignore all the reactions that does not have the gene.annotation property\n",
    "                # DISCUSS!!\n",
    "                if gene.annotation:\n",
    "                    if 'uniprot' not in gene.annotation:\n",
    "                        if 'goa' in gene.annotation:\n",
    "                            protein_id = gene.annotation['goa']\n",
    "                            # print(\"HERE\")\n",
    "                        else:\n",
    "                            break\n",
    "                    else:\n",
    "                        protein_id = gene.annotation['uniprot'][0]\n",
    "                        # print(\"HERERERERERERERER\")\n",
    "\n",
    "                    # create proteomics dict\n",
    "                    # Adding noise which is 5% of the signal data. signal + signal*0.05 = signal*1.05\n",
    "                    # print(rxnId)\n",
    "                    # print(solution.fluxes)\n",
    "                    # print(type(solution.fluxes))\n",
    "                    # print(solution.fluxes[rxnId])\n",
    "                    # print(protein_id)\n",
    "\n",
    "                    proteomics[protein_id] = (solution.fluxes[rxnId]/k)*1.05\n",
    "                    fluxomics[rxnId] = solution.fluxes[rxnId]\n",
    "\n",
    "                # create transcriptomics dict\n",
    "                transcriptomics[gene.id] = (proteomics[protein_id]/q)*1.05\n",
    "\n",
    "        return proteomics, transcriptomics, fluxomics\n",
    "\n",
    "    def write_experiment_description_file(self, condition=1, line_name='WT'):\n",
    "        # create the filename\n",
    "        experiment_description_file_name = f'{OUTPUT_FILE_PATH}/experiment_description_file.csv'\n",
    "\n",
    "        #write experiment description file\n",
    "        try:\n",
    "            with open(experiment_description_file_name, 'w') as fh:\n",
    "                fh.write(f'Line Name, Line Description, Part ID, Media, Shaking Speed, Starting OD, Culture Volume, Flask Volume, Growth Temperature, Replicate Count\\n')\n",
    "                fh.write(f\"{line_name}, KEIO wild type, ABF_001327, M9, 1, 0.1, 50, 200, 30, 1\\n\")\n",
    "        except Exception as ex:\n",
    "            print(\"Error in writing file!\")\n",
    "            print(ex)\n",
    "\n",
    "        fh.close()\n",
    "\n",
    "    def write_omics_files(self, time_series_omics_data, condition=1, line_name='WT'):\n",
    "        \"\"\"\n",
    "\n",
    "        :param dataframe:\n",
    "        :param data_type:\n",
    "        :param condition:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        # create file number two: omics file\n",
    "        # TODO: Need to change the units to actual relevant units\n",
    "        unit_dict = { \"fluxomics\": 'g/L',\\\n",
    "                \"proteomics\": 'proteins/cell',\\\n",
    "                \"transcriptomics\": \"FPKM\",\\\n",
    "                \"metabolomics\": \"mg/L\"\n",
    "                }\n",
    "\n",
    "        # for each omics type data\n",
    "        for omics_type, omics_list in time_series_omics_data.items():\n",
    "            # create the filenames\n",
    "            omics_file_name: str = f'{OUTPUT_FILE_PATH}/{omics_type}_fakedata_sample_{condition}.csv'\n",
    "            \n",
    "            # open a file to write omics data for each type and for all timepoints and constraints\n",
    "            try:\n",
    "                with open(omics_file_name, 'w') as fh:\n",
    "                    fh.write(f'Line Name,Measurement Type,Time,Value,Units\\n')\n",
    "                    for omics_dict, timepoint in omics_list:\n",
    "                        dataframe = pd.DataFrame.from_dict(omics_dict, orient='index', columns=[f'{omics_type}_value'])\n",
    "                        for index, series in dataframe.iteritems():\n",
    "                            for id, value in series.iteritems():\n",
    "                                fh.write((f'{line_name},{id},{timepoint},{value},{unit_dict[omics_type]}\\n'))\n",
    "\n",
    "            except Exception as ex:\n",
    "                print(\"Error in writing file!\")\n",
    "                print(ex)\n",
    "        \n",
    "            fh.close()\n",
    "\n",
    "    def write_OD_data(self, cell, line_name='WT'):\n",
    "        # create the filename\n",
    "        OD_data_file: str = f'{OUTPUT_FILE_PATH}/OD_fakedata_sample.csv'\n",
    "\n",
    "        # write experiment description file\n",
    "        try:\n",
    "            with open(OD_data_file, 'w') as fh:\n",
    "                fh.write(f'Line Name,Measurement Type,Concentration,Units,Time,Value\\n')\n",
    "                for index, value in cell.items():\n",
    "                    # print(index, value)\n",
    "                    fh.write((f'{line_name},Optical Density,0.75,g/L,{index},{value}\\n'))\n",
    "\n",
    "        except Exception as ex:\n",
    "            print(\"Error in writing OD file\")\n",
    "            print(ex)\n",
    "        \n",
    "    def write_training_data_with_isopentenol(self, df, filename):\n",
    "        filename = f'{DATA_FILE_PATH}/{filename}'\n",
    "        df.to_csv(filename, header=True, index=False)\n",
    "\n",
    "    def write_external_metabolite(self, substrates, isopentenol_conc, filename='external_metabolites.csv', linename='WT'):\n",
    "        # create the filename\n",
    "        external_metabolites: str = f'{OUTPUT_FILE_PATH}/{filename}'\n",
    "        # get ammonium and glucose from substrates\n",
    "        glucose = substrates.loc[:, 'glc__D_e']\n",
    "        ammonium = substrates.loc[:, 'nh4_e']\n",
    "\n",
    "        try:\n",
    "            with open(external_metabolites, 'w') as fh:\n",
    "                # get ammonium and glucose from substrates\n",
    "                fh.write(f'Line Name,Measurement Type,Time,Value,Units\\n')\n",
    "                for index, value in glucose.items():\n",
    "                    fh.write((f'{linename},CID:5793,{index},{value},mg/L\\n'))\n",
    "                    \n",
    "                for index, value in ammonium.items():\n",
    "                    fh.write((f'{linename},CID:16741146,{index},{value},mg/L\\n'))\n",
    "\n",
    "                # write out isopentenol concentrations\n",
    "                for index, value in isopentenol_conc.items():\n",
    "                    fh.write((f'{linename},CID:15983957,{index},{value},mg/L\\n'))\n",
    "        \n",
    "        except Exception as ex:\n",
    "            print(\"Error in writing OD file\")\n",
    "            print(ex)\n",
    "\n",
    "    def get_random_number(self):\n",
    "        \"\"\"\n",
    "\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        random.seed(12312)\n",
    "        return random.random()\n",
    "\n",
    "    def add_random_noise(self):\n",
    "        \"\"\"\n",
    "\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "    def get_list_of_reactions(self, file_name):\n",
    "        \"\"\"\n",
    "\n",
    "        :param file_name: Name of the model file (has to be xml for now)\n",
    "        :return: None (prints the list of reactions that has mass in them)\n",
    "        \"\"\"\n",
    "\n",
    "        # Load model¶depending on the kind of file (the file has to be xml)\n",
    "        if file_name.endswith(\".xml\"):\n",
    "            model = cobra.io.read_sbml_model(file_name)\n",
    "\n",
    "        # Print out the reaction name and reaction id for all reactions related to BIOMASS production:\n",
    "        print(\"List of reactions related to BIOMASS production:\")\n",
    "        for rxn in model.reactions:\n",
    "            if rxn.name is not None and 'BIOMASS' in rxn.id:\n",
    "                print(\"{}: {}\".format(rxn.id, rxn.name))\n",
    "\n",
    "\n",
    "\n",
    "    def get_optimized_solution(self, model, reaction_id):\n",
    "        \"\"\"\n",
    "\n",
    "        :param model:\n",
    "        :param reaction_id:\n",
    "        :return solution:\n",
    "        \"\"\"\n",
    "\n",
    "        # fix the flux value to -15 as we have data for this constraint\n",
    "        model.reactions.get_by_id(reaction_id).lower_bound = self.LOWER_BOUND\n",
    "        model.reactions.get_by_id(reaction_id).upper_bound = self.UPPER_BOUND\n",
    "        # print(model.reactions.get_by_id(reaction_id))\n",
    "\n",
    "        print(\"Displaying the reaction bounds after constraining them:\")\n",
    "        print(model.reactions.get_by_id(reaction_id).bounds)\n",
    "\n",
    "        # optimizing the model for only the selected reaction   \n",
    "        # model.slim_optimize()\n",
    "\n",
    "        # optimizing model\n",
    "        solution = model.optimize()\n",
    "\n",
    "        return solution\n",
    "\n",
    "\n",
    "    def read_model(self, file_name):\n",
    "        \"\"\"\n",
    "\n",
    "        :param file_name:\n",
    "        :return model:\n",
    "        \"\"\"\n",
    "\n",
    "        # Load model¶depending on the kind of file\n",
    "        if file_name.endswith(\".xml\"):\n",
    "            model = cobra.io.read_sbml_model(file_name)\n",
    "        elif file_name.endswith(\".json\"):\n",
    "            model = cobra.io.load_json_model(file_name)\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_data_for_host(filename):\n",
    "    \"\"\"\n",
    "        Generate omics data for host and model name\n",
    "    \"\"\"\n",
    "    if HOST_NAME == 'ecoli':\n",
    "        # create instance of the E. Coli class\n",
    "        ecoli = Ecoli()\n",
    "\n",
    "        # read model file\n",
    "        model = ecoli.read_model(filename)\n",
    "\n",
    "        # generate ecoli synthetic data for model and condition\n",
    "        condition = 1\n",
    "        print('here')\n",
    "        ecoli.generate_time_series_data(model, condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iJO1366_MVA.json\n",
      "here\n",
      "Displaying the reaction bounds after constraining them:\n",
      "(-10.0, 1000.0)\n",
      "Displaying the reaction bounds after constraining them:\n",
      "(-1000.0, 1000.0)\n",
      "Displaying the reaction bounds after constraining them:\n",
      "(-200.0, 1000.0)\n",
      "Displaying the reaction bounds after constraining them:\n",
      "(-1000.0, 1000.0)\n",
      "Displaying the reaction bounds after constraining them:\n",
      "(-1000.0, 1000.0)\n",
      "Displaying the reaction bounds after constraining them:\n",
      "(-1000.0, 1000.0)\n",
      "Displaying the reaction bounds after constraining them:\n",
      "(-1000.0, 1000.0)\n",
      "Displaying the reaction bounds after constraining them:\n",
      "(-200.0, 1000.0)\n",
      "Displaying the reaction bounds after constraining them:\n",
      "(-10.0, 1000.0)\n",
      "Displaying the reaction bounds after constraining them:\n",
      "(-839.5219917959024, 1000.0)\n",
      "Displaying the reaction bounds after constraining them:\n",
      "(-76.7338840163307, 1000.0)\n",
      "Displaying the reaction bounds after constraining them:\n",
      "(-1000.0, 1000.0)\n",
      "Displaying the reaction bounds after constraining them:\n",
      "(-710.6633672620803, 1000.0)\n",
      "Displaying the reaction bounds after constraining them:\n",
      "(-1000.0, 1000.0)\n",
      "Displaying the reaction bounds after constraining them:\n",
      "(-1000.0, 1000.0)\n",
      "Displaying the reaction bounds after constraining them:\n",
      "(-76.58379245877161, 1000.0)\n",
      "Displaying the reaction bounds after constraining them:\n",
      "(-10.0, 1000.0)\n",
      "Displaying the reaction bounds after constraining them:\n",
      "(-322.0010597936704, 1000.0)\n",
      "Displaying the reaction bounds after constraining them:\n",
      "(-29.437149609232787, 1000.0)\n",
      "Displaying the reaction bounds after constraining them:\n",
      "(-1000.0, 1000.0)\n",
      "Displaying the reaction bounds after constraining them:\n",
      "(-266.0222101813918, 1000.0)\n",
      "Displaying the reaction bounds after constraining them:\n",
      "(-401.1775203276711, 1000.0)\n",
      "Displaying the reaction bounds after constraining them:\n",
      "(-1000.0, 1000.0)\n",
      "Displaying the reaction bounds after constraining them:\n",
      "(-29.229468498551384, 1000.0)\n",
      "Displaying the reaction bounds after constraining them:\n",
      "(-10.0, 1000.0)\n",
      "Displaying the reaction bounds after constraining them:\n",
      "(-123.43026946986052, 1000.0)\n",
      "Displaying the reaction bounds after constraining them:\n",
      "(-11.289574602716412, 1000.0)\n",
      "Displaying the reaction bounds after constraining them:\n",
      "(-585.7888333102011, 1000.0)\n",
      "Displaying the reaction bounds after constraining them:\n",
      "(-95.41510907262965, 1000.0)\n",
      "Displaying the reaction bounds after constraining them:\n",
      "(-153.92706306182984, 1000.0)\n",
      "Displaying the reaction bounds after constraining them:\n",
      "(-391.4271561688268, 1000.0)\n",
      "Displaying the reaction bounds after constraining them:\n",
      "(-11.05979660209155, 1000.0)\n",
      "Displaying the reaction bounds after constraining them:\n",
      "(-10.0, 1000.0)\n",
      "Displaying the reaction bounds after constraining them:\n",
      "(-47.23942127117855, 1000.0)\n",
      "Displaying the reaction bounds after constraining them:\n",
      "(-4.326419899847245, 1000.0)\n",
      "Displaying the reaction bounds after constraining them:\n",
      "(-224.76492137861484, 1000.0)\n",
      "Displaying the reaction bounds after constraining them:\n",
      "(-29.953820828785357, 1000.0)\n",
      "Displaying the reaction bounds after constraining them:\n",
      "(-59.058013964140905, 1000.0)\n",
      "Displaying the reaction bounds after constraining them:\n",
      "(-149.5945879155164, 1000.0)\n",
      "Displaying the reaction bounds after constraining them:\n",
      "(-4.088163407574143, 1000.0)\n",
      "Displaying the reaction bounds after constraining them:\n",
      "(-8.11234455601079, 1000.0)\n",
      "Displaying the reaction bounds after constraining them:\n",
      "(-18.00528597983839, 1000.0)\n",
      "Displaying the reaction bounds after constraining them:\n",
      "(-1.6546842327578979, 1000.0)\n",
      "Displaying the reaction bounds after constraining them:\n",
      "(-86.24143549623236, 1000.0)\n",
      "Displaying the reaction bounds after constraining them:\n",
      "(-4.836576407570675, 1000.0)\n",
      "Displaying the reaction bounds after constraining them:\n",
      "(-22.657124856692857, 1000.0)\n",
      "Displaying the reaction bounds after constraining them:\n",
      "(-56.80436198531299, 1000.0)\n",
      "Displaying the reaction bounds after constraining them:\n",
      "(-1.413174575862389, 1000.0)\n",
      "Displaying the reaction bounds after constraining them:\n",
      "(0.0, 1000.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cobra/util/solver.py:403 \u001b[1;31mUserWarning\u001b[0m: solver status is 'infeasible'\n",
      "/usr/local/share/jupyteruser/.virtualenvs/jbeipython3.6/lib/python3.6/site-packages/ipykernel_launcher.py:112 \u001b[1;31mRuntimeWarning\u001b[0m: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying the reaction bounds after constraining them:\n",
      "(-11.435539261593945, 1000.0)\n",
      "Displaying the reaction bounds after constraining them:\n",
      "(-1.0542687781548548, 1000.0)\n",
      "Displaying the reaction bounds after constraining them:\n",
      "(-55.111244447101335, 1000.0)\n",
      "Displaying the reaction bounds after constraining them:\n",
      "(-0.0, 1000.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/share/jupyteruser/.virtualenvs/jbeipython3.6/lib/python3.6/site-packages/ipykernel_launcher.py:112 \u001b[1;31mRuntimeWarning\u001b[0m: divide by zero encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying the reaction bounds after constraining them:\n",
      "(-14.476803483353759, 1000.0)\n",
      "Displaying the reaction bounds after constraining them:\n",
      "(-35.95174307885627, 1000.0)\n",
      "Displaying the reaction bounds after constraining them:\n",
      "(-0.8120280420812217, 1000.0)\n",
      "Displaying the reaction bounds after constraining them:\n",
      "(0.0, 1000.0)\n",
      "Displaying the reaction bounds after constraining them:\n",
      "(-11.435539261593945, 1000.0)\n",
      "Displaying the reaction bounds after constraining them:\n",
      "(-1.0542687781548548, 1000.0)\n",
      "Displaying the reaction bounds after constraining them:\n",
      "(-55.111244447101335, 1000.0)\n",
      "Displaying the reaction bounds after constraining them:\n",
      "(-0.0, 1000.0)\n",
      "Displaying the reaction bounds after constraining them:\n",
      "(-14.476803483353759, 1000.0)\n",
      "Displaying the reaction bounds after constraining them:\n",
      "(-35.95174307885627, 1000.0)\n",
      "Displaying the reaction bounds after constraining them:\n",
      "(-0.8120280420812217, 1000.0)\n",
      "Displaying the reaction bounds after constraining them:\n",
      "(0.0, 1000.0)\n",
      "Displaying the reaction bounds after constraining them:\n",
      "(-11.435539261593945, 1000.0)\n",
      "Displaying the reaction bounds after constraining them:\n",
      "(-1.0542687781548548, 1000.0)\n",
      "Displaying the reaction bounds after constraining them:\n",
      "(-55.111244447101335, 1000.0)\n",
      "Displaying the reaction bounds after constraining them:\n",
      "(-0.0, 1000.0)\n",
      "Displaying the reaction bounds after constraining them:\n",
      "(-14.476803483353759, 1000.0)\n",
      "Displaying the reaction bounds after constraining them:\n",
      "(-35.95174307885627, 1000.0)\n",
      "Displaying the reaction bounds after constraining them:\n",
      "(-0.8120280420812217, 1000.0)\n",
      "Error in writing file!\n",
      "from_dict() got an unexpected keyword argument 'columns'\n",
      "Error in writing file!\n",
      "from_dict() got an unexpected keyword argument 'columns'\n",
      "Error in writing file!\n",
      "from_dict() got an unexpected keyword argument 'columns'\n",
      "Error in writing file!\n",
      "from_dict() got an unexpected keyword argument 'columns'\n"
     ]
    }
   ],
   "source": [
    "# get time series omics data for specified host and model\n",
    "filename = user_params['modelfile']\n",
    "\n",
    "if not os.path.isdir(DATA_FILE_PATH):\n",
    "    os.mkdir(DATA_FILE_PATH)\n",
    "if not os.path.isdir(OUTPUT_FILE_PATH):\n",
    "    os.mkdir(OUTPUT_FILE_PATH)\n",
    "    \n",
    "# generate data for host\n",
    "generate_data_for_host(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JBEI-py3.6",
   "language": "python",
   "name": "jbei-py3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
